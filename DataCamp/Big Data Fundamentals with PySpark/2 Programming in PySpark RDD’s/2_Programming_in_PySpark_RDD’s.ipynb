{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 Programming in PySpark RDD’s.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN4HmsT79GG1W7lcaIC112l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villafue/Data-Science-at-Scale/blob/main/DataCamp/Big%20Data%20Fundamentals%20with%20PySpark/2%20Programming%20in%20PySpark%20RDD%E2%80%99s/2_Programming_in_PySpark_RDD%E2%80%99s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6b7yvLBpyff"
      },
      "source": [
        "# Programming in PySpark RDD’s\r\n",
        "\r\n",
        "The main abstraction Spark provides is a resilient distributed dataset (RDD), which is the fundamental and backbone data type of this engine. This chapter introduces RDDs and shows how RDDs can be created and executed using RDD Transformations and Actions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0anYzJmeBT8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}